{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74128ad5-8f01-4bc7-a4b9-235d2797c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Enforces CPU-only execution of torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Configure environment to ensure single-threaded execution.\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]= \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224dc3ca-c786-43d7-980d-1fe50ef9cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/future/u/scheerer/miniconda3/envs/xtr-eval/lib/python3.8/site-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from xtr.datasets import BEIR, BEIRDataset, LoTTE, LoTTEDataset\n",
    "from xtr.config import XTRConfig, XTRModel, XTRScaNNIndexConfig, XTRBruteForceIndexConfig, XTRFAISSIndexConfig\n",
    "from xtr.utils import xtr_tracker, canonical_index_name\n",
    "from xtr.modeling.xtr import XTR\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "NUM_RUNS_PER_EXPERIMENT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a664668-0b1a-48f9-ac2a-f502da908dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_time_str():\n",
    "    return datetime.today().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "def xtr_eval_latency(dataset, index_config, document_top_k, token_top_k):\n",
    "    index_name = canonical_index_name(dataset=dataset, index_config=index_config)\n",
    "    config = XTRConfig(index_name=index_name, model=XTRModel.BASE_EN, index_config=index_config, override=False)\n",
    "    xtr = XTR(config=config, collection=dataset.collection, device=torch.device(\"cpu\"))\n",
    "    tracker = xtr_tracker(name=index_name)\n",
    "    rankings = xtr.retrieve_docs(dataset.queries, document_top_k=document_top_k, token_top_k=token_top_k, tracker=tracker)\n",
    "    return tracker, dataset.eval(rankings)\n",
    "\n",
    "def xtr_run_configuration(dataset, index_config, document_top_k, token_top_k):\n",
    "    tracker, metrics = xtr_eval_latency(dataset, index_config, document_top_k, token_top_k)\n",
    "    configuration = {\"dataset\": dataset.name, \"index\": index_config.name,\n",
    "                     \"document_top_k\": document_top_k, \"token_top_k\": token_top_k}\n",
    "    return {\n",
    "        \"config\": configuration,\n",
    "        \"metrics\": metrics,\n",
    "        \"tracker\": tracker.as_dict()\n",
    "    }\n",
    "\n",
    "def xtr_run_configurations(datasets, index_configs, document_top_k, token_top_k_values, label):\n",
    "    ctime = current_time_str()\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    filename = os.path.join(\"results\", f\"run_{label}_{ctime}.json\")\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        for index_config in index_configs:\n",
    "            for token_top_k in token_top_k_values:\n",
    "                results.append(xtr_run_configuration(dataset, index_config, document_top_k=document_top_k, token_top_k=token_top_k))\n",
    "                with open(filename, \"w\") as file:\n",
    "                    json.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7d73fa-877d-4873-837a-a3183c7b8af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6915eed9651439790383ec026397668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Preparing corpus for BEIR BEIR.SCIFACT/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 5183/5183 [00:00<00:00, 569607.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing index from /future/u/scheerer/home/data/xtr-eval/indexes/BEIR.SCIFACT.split=test.XTRIndexType.SCANN.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 38:5: text format contains deprecated field \"min_cluster_size\"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:58<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing index from /future/u/scheerer/home/data/xtr-eval/indexes/BEIR.SCIFACT.split=test.XTRIndexType.SCANN.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 38:5: text format contains deprecated field \"min_cluster_size\"\n",
      "  7%|██████▋                                                                                              | 20/300 [03:42<51:53, 11.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m TOKEN_TOP_K_VALUES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1_000\u001b[39m, \u001b[38;5;241m40_0000\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_RUNS_PER_EXPERIMENT):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mxtr_run_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASETS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINDEX_CONFIGS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdocument_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_top_k_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOKEN_TOP_K_VALUES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscann\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m, in \u001b[0;36mxtr_run_configurations\u001b[0;34m(datasets, index_configs, document_top_k, token_top_k_values, label)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index_config \u001b[38;5;129;01min\u001b[39;00m index_configs:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token_top_k \u001b[38;5;129;01min\u001b[39;00m token_top_k_values:\n\u001b[0;32m---> 30\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mxtr_run_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_top_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_top_k\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     32\u001b[0m             json\u001b[38;5;241m.\u001b[39mdump(results, file)\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mxtr_run_configuration\u001b[0;34m(dataset, index_config, document_top_k, token_top_k)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mxtr_run_configuration\u001b[39m(dataset, index_config, document_top_k, token_top_k):\n\u001b[0;32m---> 13\u001b[0m     tracker, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mxtr_eval_latency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_top_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_top_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     configuration \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index_config\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     15\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument_top_k\u001b[39m\u001b[38;5;124m\"\u001b[39m: document_top_k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_top_k\u001b[39m\u001b[38;5;124m\"\u001b[39m: token_top_k}\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: configuration,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtracker\u001b[39m\u001b[38;5;124m\"\u001b[39m: tracker\u001b[38;5;241m.\u001b[39mas_dict()\n\u001b[1;32m     20\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m, in \u001b[0;36mxtr_eval_latency\u001b[0;34m(dataset, index_config, document_top_k, token_top_k)\u001b[0m\n\u001b[1;32m      7\u001b[0m xtr \u001b[38;5;241m=\u001b[39m XTR(config\u001b[38;5;241m=\u001b[39mconfig, collection\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mcollection, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m tracker \u001b[38;5;241m=\u001b[39m xtr_tracker(name\u001b[38;5;241m=\u001b[39mindex_name)\n\u001b[0;32m----> 9\u001b[0m rankings \u001b[38;5;241m=\u001b[39m \u001b[43mxtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_top_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_top_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tracker, dataset\u001b[38;5;241m.\u001b[39meval(rankings)\n",
      "File \u001b[0;32m~/development/xtr-eval/xtr/modeling/xtr.py:361\u001b[0m, in \u001b[0;36mXTR.retrieve_docs\u001b[0;34m(self, query, token_top_k, document_top_k, return_text, tracker)\u001b[0m\n\u001b[1;32m    358\u001b[0m batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_search_tokens([query_text], token_top_k\u001b[38;5;241m=\u001b[39mtoken_top_k, leaves_to_search\u001b[38;5;241m=\u001b[39mleaves_to_search,\n\u001b[1;32m    359\u001b[0m                                          pre_reorder_num_neighbors\u001b[38;5;241m=\u001b[39mpre_reorder_num_neighbors, tracker\u001b[38;5;241m=\u001b[39mtracker)\n\u001b[1;32m    360\u001b[0m batch_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_missing_similarity(batch_result, tracker\u001b[38;5;241m=\u001b[39mtracker)\n\u001b[0;32m--> 361\u001b[0m batch_ranking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_top_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# TODO(jlscheerer) Fix this for multiple queries\u001b[39;00m\n\u001b[1;32m    364\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_document_text(batch_ranking) \u001b[38;5;28;01mif\u001b[39;00m return_text \u001b[38;5;28;01melse\u001b[39;00m batch_ranking\n",
      "File \u001b[0;32m~/development/xtr-eval/xtr/modeling/xtr.py:297\u001b[0m, in \u001b[0;36mXTR._aggregate_scores\u001b[0;34m(self, batch_result, batch_ems, document_top_k, tracker)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 did2scores[docid][qtoken_with_idx] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m did2scores\n\u001b[0;32m--> 297\u001b[0m batch_did2scores \u001b[38;5;241m=\u001b[39m [get_did2scores(qtokens, neighbors, scores) \u001b[38;5;28;01mfor\u001b[39;00m qtokens, neighbors, scores \u001b[38;5;129;01min\u001b[39;00m batch_result]\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_ems\u001b[39m(did2scores, query_tokens, ems):\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# |Q| x |Q|k' (assuming most docid is unique)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m qtoken_idx, qtoken \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(query_tokens):\n",
      "File \u001b[0;32m~/development/xtr-eval/xtr/modeling/xtr.py:297\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 did2scores[docid][qtoken_with_idx] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m did2scores\n\u001b[0;32m--> 297\u001b[0m batch_did2scores \u001b[38;5;241m=\u001b[39m [\u001b[43mget_did2scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m qtokens, neighbors, scores \u001b[38;5;129;01min\u001b[39;00m batch_result]\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_ems\u001b[39m(did2scores, query_tokens, ems):\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# |Q| x |Q|k' (assuming most docid is unique)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m qtoken_idx, qtoken \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(query_tokens):\n",
      "File \u001b[0;32m~/development/xtr-eval/xtr/modeling/xtr.py:289\u001b[0m, in \u001b[0;36mXTR._aggregate_scores.<locals>.get_did2scores\u001b[0;34m(query_tokens, all_neighbors, all_scores)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    288\u001b[0m docid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtid2did[doc_token_id]\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdocid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdid2scores\u001b[49m:\n\u001b[1;32m    290\u001b[0m     did2scores[docid] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    291\u001b[0m qtoken_with_idx \u001b[38;5;241m=\u001b[39m (qtoken_idx, qtoken)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASETS = [BEIRDataset(dataset=BEIR.SCIFACT, datasplit=\"test\"),\n",
    "            LoTTEDataset(dataset=LoTTE.LIFESTYLE, datasplit=\"test\"),\n",
    "            LoTTEDataset(dataset=LoTTE.TECHNOLOGY, datasplit=\"test\")]\n",
    "INDEX_CONFIGS = [XTRScaNNIndexConfig()]\n",
    "TOKEN_TOP_K_VALUES = [1_000, 40_0000]\n",
    "\n",
    "for _ in range(NUM_RUNS_PER_EXPERIMENT):\n",
    "    xtr_run_configurations(datasets=DATASETS, index_configs=INDEX_CONFIGS,\n",
    "                           document_top_k=100, token_top_k_values=TOKEN_TOP_K_VALUES, label=\"scann\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
